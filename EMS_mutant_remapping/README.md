## Exome capture sequencing

Exome capture sequencing data was generated by [Krasileva et al., 2017](https://www.pnas.org/doi/10.1073/pnas.1619268114) and available through [PRJNA258539](https://www.ncbi.nlm.nih.gov/sra?linkname=bioproject_sra_all&from_uid=258539). There are 1,479 SRA experiments deposited under this BioProject. 39 of them are additional libraries deposited existing Kronos mutants. We are therefore targeting to analyze 1,440 mutants. We retrived the SRA accession of the experiments and obtained corresponding SRR accessions as below.

Obtain SRR accessions for the given SRX accessions.
```
#this can be done with a python script
from pysradb import SRAweb

for line in open('SRA.list', 'r'):
  mutant, srx = line.split('\t')
  srr = db.srx_to_srr([srx])['run_accession'].iloc[0]
  print(f'{mutant} {srx} {srr}')
```

This information is available in **SRA.list** and looks like this.
```
Mutant ID	SRA accession	SRR accession
Kronos0-1	SRX688079	SRR1559585
Kronos0-1	SRX688078	SRR1559584
Kronos0-2	SRX688080	SRR1559586
Kronos1000	SRX688377	SRR1559883
Kronos1002	SRX688378	SRR1559884
```


${srr} obtained from the previous step can be set up as ${accession}. Download the sequencing data from the Sequence Read Archive with sra-toolkit v3.1.1. 
```
sratoolkit.3.1.1-centos_linux64/bin/prefetch ${accession}
sratoolkit.3.1.1-centos_linux64/bin/fasterq-dump -O . -e ${Numthreads} ${accession}
```

Filter the sequencing data with fastp v0.23.4.
```
fastp --in1 ${accession}_1.fastq --in2 ${accession}_2.fastq --out1 ${accession}.1.filtered.fq --out2 ${accession}.2.filtered.fq --thread 16 -q 20
```

Align the reads to the broken Kronos genome with bwa aln v0.7.18-r1243-dirty.
```
# ${x} is either 1 or 2 for R1 and R2 in the paired-end library
bwa aln -t ${Numthreads} ${reference_dir}/Kronos -f ${accession}.${x}.sai ${accession}.${x}.filtered.fq
bwa sampe -N 10 -n 10 -f ${accession}.sam ${reference_dir}/Kronos ${accession}.1.sai ${accession}.2.sai ${accession}.1.filtered.fq ${accession}.2.filtered.fq
```

Sort the alignment file with samtools v1.20 and remove duplicates with picard v3.0.0
```
samtools view -@ ${Numthreads} -h -b ${accession}.sam | samtools sort -@ ${Numthreads} > ${accession}.sorted.bam
samtools index ${accession}.sorted.bam

#occasionally, the bam file may contains records that picard does not like to process.
#ALIDATION_STRINGENCY=LENIENT can be added to skip those alignments
picard MarkDuplicates REMOVE_DUPLICATES=true I=${accession}.sorted.bam O=${accession}.sorted.rmdup.bam M=${accession}.rmdup.txt
```

Some mutants have two sequencing datasets deposited. Let's merge those into single bam files. 
```
while read mutant lib1 lib2; do
     samtools merge -@ 56 -o ../sorted.rmdup.bam_files/${lib1}.sorted.rmdup.bam ${lib1}.sorted.rmdup.bam ${lib2}.sorted.rmdup.bam
 done < merge.list
```

By this step, we have 1,440 bam files ready to be processed with the MAPS pipeline. We try to process about 24 samples in a single batch. During Kronos mutant sequencing library peparation, a batch of 8 mutants was typically processed together and three batches were sequenced together. But there are some variations in number of mutants prepared, and some sequencing datasets are not available in the NCBI. As we do not want to split datasets from a single batch into different groups for the MAPS. The number of members in the processing groups will slightly vary. This information can be found in **MAPS_groups.list**.

```
#create folders and move bam files
for i in {1..60}; do mkdir MAPS-${i}; done
cat MAPS_groups.list | while read line; do
    accession=$(echo $line | awk '{print $4}')
    i=$(echo $line | awk '{print $6}')
    mv ${accession}.sorted.rmdup.bam MAPS-${i}/
done
```

